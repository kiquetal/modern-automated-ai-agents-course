<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/langchain.md">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/langchain.md" />
              <option name="updatedContent" value="# Using CrewAI with LangChain Tools&#10;&#10;## Architecture Diagram&#10;&#10;```mermaid&#10;graph TD&#10;    subgraph &quot;CrewAI Framework&quot;&#10;        A[Agent 1: Researcher] &#10;        B[Agent 2: Analyst]&#10;        C[Agent 3: Writer]&#10;        D[Crew Manager]&#10;        E[Task Queue]&#10;    end&#10;    &#10;    subgraph &quot;LangChain Tools&quot;&#10;        F[Document Loaders]&#10;        G[Text Splitters]&#10;        H[Vector Stores]&#10;        I[Retrievers]&#10;        J[LLM Chains]&#10;        K[Memory]&#10;    end&#10;    &#10;    subgraph &quot;Data Sources&quot;&#10;        L[Wikipedia]&#10;        M[Web Pages]&#10;        N[PDFs]&#10;        O[Databases]&#10;    end&#10;    &#10;    subgraph &quot;LLM Providers&quot;&#10;        P[OpenAI]&#10;        Q[Anthropic]&#10;        R[Google]&#10;        S[Others]&#10;    end&#10;    &#10;    %% Connections&#10;    L --&gt; F&#10;    M --&gt; F&#10;    N --&gt; F&#10;    O --&gt; F&#10;    &#10;    F --&gt; G&#10;    G --&gt; H&#10;    H --&gt; I&#10;    &#10;    A --&gt; J&#10;    B --&gt; J&#10;    C --&gt; J&#10;    &#10;    J --&gt; P&#10;    J --&gt; Q&#10;    J --&gt; R&#10;    J --&gt; S&#10;    &#10;    I --&gt; A&#10;    I --&gt; B&#10;    I --&gt; C&#10;    &#10;    K --&gt; A&#10;    K --&gt; B&#10;    K --&gt; C&#10;    &#10;    A --&gt; D&#10;    B --&gt; D&#10;    C --&gt; D&#10;    &#10;    D --&gt; E&#10;    E --&gt; A&#10;    E --&gt; B&#10;    E --&gt; C&#10;```&#10;&#10;## Integration Flow&#10;&#10;1. **Data Ingestion**&#10;   - LangChain document loaders fetch content from various sources (Wikipedia, web pages, etc.)&#10;   - Text splitters break down content into manageable chunks&#10;   - Vector stores index content for efficient retrieval&#10;&#10;2. **Agent Setup in CrewAI**&#10;   - Define specialized agents with specific roles (e.g., Researcher, Analyst, Writer)&#10;   - Equip agents with LangChain tools for processing and retrieving information&#10;   - Configure agents with appropriate LLM backends (OpenAI, Anthropic, etc.)&#10;&#10;3. **Task Execution**&#10;   - CrewAI Crew Manager orchestrates the workflow between agents&#10;   - Agents use LangChain chains to process information&#10;   - Tasks are delegated based on agent specialization&#10;&#10;4. **Information Flow**&#10;   - Retrieved data flows from LangChain retrievers to CrewAI agents&#10;   - Agents process information using LLM-powered reasoning&#10;   - Results are passed between agents through the Crew Manager&#10;&#10;## Example Implementation&#10;&#10;```python&#10;from crewai import Agent, Task, Crew&#10;from langchain_community.document_loaders import WebBaseLoader&#10;from langchain.text_splitter import RecursiveCharacterTextSplitter&#10;from langchain_openai import ChatOpenAI&#10;&#10;# 1. Setup LangChain components&#10;loader = WebBaseLoader(&quot;https://en.wikipedia.org/wiki/Artificial_intelligence&quot;)&#10;documents = loader.load()&#10;text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)&#10;splits = text_splitter.split_documents(documents)&#10;&#10;# 2. Initialize LLM&#10;llm = ChatOpenAI(model=&quot;gpt-4o&quot;)&#10;&#10;# 3. Define CrewAI agents&#10;researcher = Agent(&#10;    role=&quot;Researcher&quot;,&#10;    goal=&quot;Extract key information from documents&quot;,&#10;    backstory=&quot;You are an expert at finding and organizing information&quot;,&#10;    verbose=True,&#10;    llm=llm&#10;)&#10;&#10;analyst = Agent(&#10;    role=&quot;Analyst&quot;,&#10;    goal=&quot;Analyze information and identify patterns&quot;,&#10;    backstory=&quot;You excel at making sense of complex information&quot;,&#10;    verbose=True,&#10;    llm=llm&#10;)&#10;&#10;# 4. Define tasks&#10;research_task = Task(&#10;    description=&quot;Review the AI documents and extract key concepts&quot;,&#10;    agent=researcher,&#10;    context=str(splits)&#10;)&#10;&#10;analysis_task = Task(&#10;    description=&quot;Analyze the research findings and identify trends&quot;,&#10;    agent=analyst&#10;)&#10;&#10;# 5. Create and run the crew&#10;crew = Crew(&#10;    agents=[researcher, analyst],&#10;    tasks=[research_task, analysis_task],&#10;    verbose=2&#10;)&#10;&#10;result = crew.kickoff()&#10;```&#10;&#10;This architecture allows for powerful AI workflows that combine the multi-agent capabilities of CrewAI with the extensive toolkit provided by LangChain.&#10;&#10;## Wikipedia Question Answering Implementation&#10;&#10;The `wikipedia_qa.py` script demonstrates a practical implementation of CrewAI with LangChain to create a Wikipedia question-answering system. This implementation showcases how to combine these frameworks to build a specialized knowledge extraction and analysis system.&#10;&#10;### Implementation Diagram&#10;&#10;```mermaid&#10;sequenceDiagram&#10;    participant User&#10;    participant WRC as WikipediaResearchCrew&#10;    participant LCL as LangChain Loader&#10;    participant LCS as LangChain Splitter&#10;    participant RA as Researcher Agent&#10;    participant AA as Analyst Agent&#10;    participant Wiki as Wikipedia&#10;&#10;    User-&gt;&gt;WRC: Initialize(wiki_url, questions)&#10;    activate WRC&#10;    &#10;    WRC-&gt;&gt;WRC: setup_crew()&#10;    &#10;    WRC-&gt;&gt;LCL: WebBaseLoader(wiki_url)&#10;    activate LCL&#10;    LCL-&gt;&gt;Wiki: Fetch Page Content&#10;    Wiki--&gt;&gt;LCL: HTML Content&#10;    LCL-&gt;&gt;WRC: documents&#10;    deactivate LCL&#10;    &#10;    WRC-&gt;&gt;LCS: RecursiveCharacterTextSplitter&#10;    activate LCS&#10;    LCS-&gt;&gt;LCS: Split documents&#10;    LCS--&gt;&gt;WRC: document_chunks&#10;    deactivate LCS&#10;    &#10;    WRC-&gt;&gt;RA: Assign research_task&#10;    note over RA: Extract key information&lt;br&gt;from Wikipedia content&#10;    &#10;    WRC-&gt;&gt;AA: Prepare analysis_task&#10;    note over AA: Format questions&lt;br&gt;for analysis&#10;    &#10;    WRC-&gt;&gt;WRC: Build context from chunks&#10;    &#10;    WRC-&gt;&gt;+RA: Execute research_task&#10;    RA--&gt;&gt;-AA: Research findings&#10;    &#10;    WRC-&gt;&gt;+AA: Execute analysis_task&#10;    AA--&gt;&gt;-WRC: Detailed answers&#10;    &#10;    WRC--&gt;&gt;User: Final results&#10;    deactivate WRC&#10;```&#10;&#10;### Key Components&#10;&#10;1. **Class Structure**&#10;   - The solution is encapsulated in a `WikipediaResearchCrew` class&#10;   - The class manages the entire workflow from content fetching to answer generation&#10;&#10;2. **Content Retrieval**&#10;   - Uses LangChain's `WebBaseLoader` to fetch Wikipedia content&#10;   - Implements `RecursiveCharacterTextSplitter` to divide content into manageable chunks&#10;   - Preserves document structure for context-aware processing&#10;&#10;3. **Agent Configuration**&#10;   - **Wikipedia Researcher Agent**: Specialized in extracting key information from Wikipedia articles&#10;   - **Content Analyst Agent**: Focused on understanding the extracted information and answering specific questions&#10;   - Both agents are configured with OpenAI's GPT-4o model for advanced reasoning&#10;&#10;4. **Task Orchestration**&#10;   - Research task provides the Wikipedia content as context to the researcher agent&#10;   - Analysis task takes the researcher's output and uses it to answer specific questions&#10;   - Tasks are sequentially executed with the output of one feeding into the next&#10;&#10;5. **Dynamic Question Handling**&#10;   - Accepts any Wikipedia URL as input&#10;   - Takes a list of user-defined questions about the content&#10;   - Formats questions into the task description for the analyst agent&#10;&#10;### Example Usage&#10;&#10;The script includes a demonstration that:&#10;1. Targets the Wikipedia article on Artificial Intelligence&#10;2. Asks four specific questions about AI history, approaches, ethics, and industry applications&#10;3. Runs the crew to process the article and generate detailed answers&#10;4. Prints the final results to the console&#10;&#10;### Implementation Benefits&#10;&#10;- **Separation of Concerns**: Each agent has a specific role in the information processing pipeline&#10;- **Flexible Content Source**: Can be adapted to work with any Wikipedia article&#10;- **Customizable Questions**: Users can specify any questions relevant to their research needs&#10;- **Context-Aware Responses**: The system maintains context throughout the processing chain&#10;&#10;This implementation demonstrates how CrewAI's multi-agent orchestration combined with LangChain's document processing capabilities creates a powerful system for extracting and analyzing information from web content." />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>